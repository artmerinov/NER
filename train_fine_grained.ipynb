{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "from utils import set_random_seed, Config, load_ner_config\n",
    "from dataset import io2df, io2bio, padding, NERDataset\n",
    "from model import BiLSTM_CRF\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "set_random_seed(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TR_PATH': 'data/supervised/train.txt',\n",
       " 'VA_PATH': 'data/supervised/dev.txt',\n",
       " 'TE_PATH': 'data/supervised/test.txt',\n",
       " 'SEQ_LEN': 64,\n",
       " 'BATCH_SIZE': 128,\n",
       " 'LR': 0.001,\n",
       " 'REG_LAMBDA': 0.0001,\n",
       " 'MAX_GRAD_NORM': 100,\n",
       " 'NUM_EPOCHS': 10,\n",
       " 'EMBED_SIZE': 128,\n",
       " 'HIDDEN_SIZE': 128,\n",
       " 'DROPOUT': 0.5}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config('config.yaml')\n",
    "config.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3359329/3359329 [00:04<00:00, 724331.02it/s]\n",
      "100%|██████████| 482037/482037 [00:00<00:00, 486813.09it/s]\n"
     ]
    }
   ],
   "source": [
    "tr_titles = io2df(config.TR_PATH)\n",
    "va_titles = io2df(config.VA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags_fine_grained</th>\n",
       "      <th>tags_coarse_grained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Paul, International, airport, .]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[It, starred, Hicks, 's, wife, ,, Ellaline, Te...</td>\n",
       "      <td>[O, O, person-artist/author, O, O, O, person-a...</td>\n",
       "      <td>[O, O, person, O, O, O, person, person, O, per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[``, Time, ``, magazine, said, the, film, was,...</td>\n",
       "      <td>[O, art-writtenart, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[O, art, O, O, O, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Pakistani, scientists, and, engineers, ', wor...</td>\n",
       "      <td>[O, O, O, O, O, O, O, organization-other, O, O...</td>\n",
       "      <td>[O, O, O, O, O, O, O, organization, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[In, February, 2008, ,, Church, 's, Chicken, e...</td>\n",
       "      <td>[O, O, O, O, organization-company, organizatio...</td>\n",
       "      <td>[O, O, O, O, organization, organization, organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131762</th>\n",
       "      <td>131762</td>\n",
       "      <td>[In, response, ,, the, states, who, had, ratif...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, other-law, O, O, o...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, other, O, O, organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131763</th>\n",
       "      <td>131763</td>\n",
       "      <td>[They, have, long, been, used, as, containers,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131764</th>\n",
       "      <td>131764</td>\n",
       "      <td>[In, 1911, he, came, into, possession, of, the...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131765</th>\n",
       "      <td>131765</td>\n",
       "      <td>[The, Lutici, tribes, in, 983, formed, the, Li...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131766</th>\n",
       "      <td>131766</td>\n",
       "      <td>[Afterward, ,, he, was, arrested, as, a, Russi...</td>\n",
       "      <td>[O, O, O, O, O, O, O, location-GPE, O, O, loca...</td>\n",
       "      <td>[O, O, O, O, O, O, O, location, O, O, location...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131767 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                             tokens  \\\n",
       "0            0                  [Paul, International, airport, .]   \n",
       "1            1  [It, starred, Hicks, 's, wife, ,, Ellaline, Te...   \n",
       "2            2  [``, Time, ``, magazine, said, the, film, was,...   \n",
       "3            3  [Pakistani, scientists, and, engineers, ', wor...   \n",
       "4            4  [In, February, 2008, ,, Church, 's, Chicken, e...   \n",
       "...        ...                                                ...   \n",
       "131762  131762  [In, response, ,, the, states, who, had, ratif...   \n",
       "131763  131763  [They, have, long, been, used, as, containers,...   \n",
       "131764  131764  [In, 1911, he, came, into, possession, of, the...   \n",
       "131765  131765  [The, Lutici, tribes, in, 983, formed, the, Li...   \n",
       "131766  131766  [Afterward, ,, he, was, arrested, as, a, Russi...   \n",
       "\n",
       "                                        tags_fine_grained  \\\n",
       "0                                            [O, O, O, O]   \n",
       "1       [O, O, person-artist/author, O, O, O, person-a...   \n",
       "2       [O, art-writtenart, O, O, O, O, O, O, O, O, O,...   \n",
       "3       [O, O, O, O, O, O, O, organization-other, O, O...   \n",
       "4       [O, O, O, O, organization-company, organizatio...   \n",
       "...                                                   ...   \n",
       "131762  [O, O, O, O, O, O, O, O, O, other-law, O, O, o...   \n",
       "131763  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "131764   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "131765  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "131766  [O, O, O, O, O, O, O, location-GPE, O, O, loca...   \n",
       "\n",
       "                                      tags_coarse_grained  \n",
       "0                                            [O, O, O, O]  \n",
       "1       [O, O, person, O, O, O, person, person, O, per...  \n",
       "2       [O, art, O, O, O, O, O, O, O, O, O, O, O, O, O...  \n",
       "3       [O, O, O, O, O, O, O, organization, O, O, O, O...  \n",
       "4       [O, O, O, O, organization, organization, organ...  \n",
       "...                                                   ...  \n",
       "131762  [O, O, O, O, O, O, O, O, O, other, O, O, organ...  \n",
       "131763  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "131764   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "131765  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "131766  [O, O, O, O, O, O, O, location, O, O, location...  \n",
       "\n",
       "[131767 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag -> tagID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG2IDX = load_ner_config('ner_tags/ner_fine_grained.json')\n",
    "IDX2TAG = {i: t for t, i in TAG2IDX.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PAD': 0,\n",
       " 'O': 1,\n",
       " 'art-broadcastprogram': 2,\n",
       " 'art-film': 3,\n",
       " 'art-music': 4,\n",
       " 'art-other': 5,\n",
       " 'art-painting': 6,\n",
       " 'art-writtenart': 7,\n",
       " 'building-airport': 8,\n",
       " 'building-hospital': 9,\n",
       " 'building-hotel': 10,\n",
       " 'building-library': 11,\n",
       " 'building-other': 12,\n",
       " 'building-restaurant': 13,\n",
       " 'building-sportsfacility': 14,\n",
       " 'building-theater': 15,\n",
       " 'event-attack/battle/war/militaryconflict': 16,\n",
       " 'event-disaster': 17,\n",
       " 'event-election': 18,\n",
       " 'event-other': 19,\n",
       " 'event-protest': 20,\n",
       " 'event-sportsevent': 21,\n",
       " 'location-GPE': 22,\n",
       " 'location-bodiesofwater': 23,\n",
       " 'location-island': 24,\n",
       " 'location-mountain': 25,\n",
       " 'location-other': 26,\n",
       " 'location-park': 27,\n",
       " 'location-road/railway/highway/transit': 28,\n",
       " 'organization-company': 29,\n",
       " 'organization-education': 30,\n",
       " 'organization-government/governmentagency': 31,\n",
       " 'organization-media/newspaper': 32,\n",
       " 'organization-other': 33,\n",
       " 'organization-politicalparty': 34,\n",
       " 'organization-religion': 35,\n",
       " 'organization-showorganization': 36,\n",
       " 'organization-sportsleague': 37,\n",
       " 'organization-sportsteam': 38,\n",
       " 'other-astronomything': 39,\n",
       " 'other-award': 40,\n",
       " 'other-biologything': 41,\n",
       " 'other-chemicalthing': 42,\n",
       " 'other-currency': 43,\n",
       " 'other-disease': 44,\n",
       " 'other-educationaldegree': 45,\n",
       " 'other-god': 46,\n",
       " 'other-language': 47,\n",
       " 'other-law': 48,\n",
       " 'other-livingthing': 49,\n",
       " 'other-medical': 50,\n",
       " 'person-actor': 51,\n",
       " 'person-artist/author': 52,\n",
       " 'person-athlete': 53,\n",
       " 'person-director': 54,\n",
       " 'person-other': 55,\n",
       " 'person-politician': 56,\n",
       " 'person-scholar': 57,\n",
       " 'person-soldier': 58,\n",
       " 'product-airplane': 59,\n",
       " 'product-car': 60,\n",
       " 'product-food': 61,\n",
       " 'product-game': 62,\n",
       " 'product-other': 63,\n",
       " 'product-ship': 64,\n",
       " 'product-software': 65,\n",
       " 'product-train': 66,\n",
       " 'product-weapon': 67}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAG2IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_titles['tags_ids'] = tr_titles['tags_fine_grained'].transform(lambda x: [TAG2IDX[tag] for tag in x])\n",
    "va_titles['tags_ids'] = va_titles['tags_fine_grained'].transform(lambda x: [TAG2IDX[tag] for tag in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token -> tokenID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3359329/3359329 [00:03<00:00, 902990.85it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34705"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_token_cntr(filepath):\n",
    "\n",
    "    token_cntr = Counter()\n",
    "    num_lines = sum(1 for _ in open(filepath, encoding=\"utf-8\"))\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f, total=num_lines):\n",
    "            line = line.strip().split()\n",
    "            if line:\n",
    "                token, fine_tag = line\n",
    "                token_cntr[token] += 1\n",
    "    \n",
    "    return token_cntr\n",
    "\n",
    "token_cntr = calc_token_cntr(filepath=config.TR_PATH)\n",
    "\n",
    "top_tokens = [token for token, cnt in token_cntr.most_common() if cnt >= 5]\n",
    "TOKEN2IDX = {token: i + 2 for i, token in enumerate(top_tokens)}\n",
    "TOKEN2IDX['PAD'] = 0\n",
    "TOKEN2IDX['UKN'] = 1\n",
    "\n",
    "with open('tokenizers/token2idx.json', 'w') as f:\n",
    "    json.dump(TOKEN2IDX, f, indent=4)\n",
    "\n",
    "len(TOKEN2IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_titles['tokens_ids'] = tr_titles['tokens'].transform(lambda x: [TOKEN2IDX[token] if token in TOKEN2IDX else TOKEN2IDX['UKN'] for token in x])\n",
    "va_titles['tokens_ids'] = va_titles['tokens'].transform(lambda x: [TOKEN2IDX[token] if token in TOKEN2IDX else TOKEN2IDX['UKN'] for token in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_titles['tokens_ids'] = tr_titles['tokens_ids'].transform(padding, max_len=config.SEQ_LEN)\n",
    "tr_titles['tags_ids'] = tr_titles['tags_ids'].transform(padding, max_len=config.SEQ_LEN)\n",
    "\n",
    "va_titles['tokens_ids'] = va_titles['tokens_ids'].transform(padding, max_len=config.SEQ_LEN)\n",
    "va_titles['tags_ids'] = va_titles['tags_ids'].transform(padding, max_len=config.SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags_fine_grained</th>\n",
       "      <th>tags_coarse_grained</th>\n",
       "      <th>tags_ids</th>\n",
       "      <th>tokens_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Paul, International, airport, .]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[586, 170, 711, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[It, starred, Hicks, 's, wife, ,, Ellaline, Te...</td>\n",
       "      <td>[O, O, person-artist/author, O, O, O, person-a...</td>\n",
       "      <td>[O, O, person, O, O, O, person, person, O, per...</td>\n",
       "      <td>[1, 1, 52, 1, 1, 1, 51, 51, 1, 51, 51, 1, 0, 0...</td>\n",
       "      <td>[35, 1601, 15202, 22, 659, 3, 1, 1, 6, 5586, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[``, Time, ``, magazine, said, the, film, was,...</td>\n",
       "      <td>[O, art-writtenart, O, O, O, O, O, O, O, O, O,...</td>\n",
       "      <td>[O, art, O, O, O, O, O, O, O, O, O, O, O, O, O...</td>\n",
       "      <td>[1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[10, 2065, 10, 1045, 381, 2, 76, 11, 10, 9, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Pakistani, scientists, and, engineers, ', wor...</td>\n",
       "      <td>[O, O, O, O, O, O, O, organization-other, O, O...</td>\n",
       "      <td>[O, O, O, O, O, O, O, organization, O, O, O, O...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 33, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[5323, 5587, 6, 6537, 59, 603, 21, 1, 78, 1076...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[In, February, 2008, ,, Church, 's, Chicken, e...</td>\n",
       "      <td>[O, O, O, O, organization-company, organizatio...</td>\n",
       "      <td>[O, O, O, O, organization, organization, organ...</td>\n",
       "      <td>[1, 1, 1, 1, 29, 29, 29, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[25, 187, 139, 3, 340, 22, 6282, 922, 2, 541, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131762</th>\n",
       "      <td>131762</td>\n",
       "      <td>[In, response, ,, the, states, who, had, ratif...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, other-law, O, O, o...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, other, O, O, organ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 48, 1, 1, 33, 33, ...</td>\n",
       "      <td>[25, 1235, 3, 2, 1110, 49, 40, 8312, 2, 14192,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131763</th>\n",
       "      <td>131763</td>\n",
       "      <td>[They, have, long, been, used, as, containers,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[198, 53, 470, 47, 68, 17, 19121, 16, 8367, 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131764</th>\n",
       "      <td>131764</td>\n",
       "      <td>[In, 1911, he, came, into, possession, of, the...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[25, 2509, 29, 383, 57, 5299, 5, 2, 1, 28249, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131765</th>\n",
       "      <td>131765</td>\n",
       "      <td>[The, Lutici, tribes, in, 983, formed, the, Li...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[12, 1, 3938, 7, 1, 391, 2, 1, 17656, 3, 5239,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131766</th>\n",
       "      <td>131766</td>\n",
       "      <td>[Afterward, ,, he, was, arrested, as, a, Russi...</td>\n",
       "      <td>[O, O, O, O, O, O, O, location-GPE, O, O, loca...</td>\n",
       "      <td>[O, O, O, O, O, O, O, location, O, O, location...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 22, 1, 1, 22, 1, 1, 1, 1...</td>\n",
       "      <td>[24359, 3, 29, 11, 2684, 17, 9, 604, 7094, 19,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131767 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                             tokens  \\\n",
       "0            0                  [Paul, International, airport, .]   \n",
       "1            1  [It, starred, Hicks, 's, wife, ,, Ellaline, Te...   \n",
       "2            2  [``, Time, ``, magazine, said, the, film, was,...   \n",
       "3            3  [Pakistani, scientists, and, engineers, ', wor...   \n",
       "4            4  [In, February, 2008, ,, Church, 's, Chicken, e...   \n",
       "...        ...                                                ...   \n",
       "131762  131762  [In, response, ,, the, states, who, had, ratif...   \n",
       "131763  131763  [They, have, long, been, used, as, containers,...   \n",
       "131764  131764  [In, 1911, he, came, into, possession, of, the...   \n",
       "131765  131765  [The, Lutici, tribes, in, 983, formed, the, Li...   \n",
       "131766  131766  [Afterward, ,, he, was, arrested, as, a, Russi...   \n",
       "\n",
       "                                        tags_fine_grained  \\\n",
       "0                                            [O, O, O, O]   \n",
       "1       [O, O, person-artist/author, O, O, O, person-a...   \n",
       "2       [O, art-writtenart, O, O, O, O, O, O, O, O, O,...   \n",
       "3       [O, O, O, O, O, O, O, organization-other, O, O...   \n",
       "4       [O, O, O, O, organization-company, organizatio...   \n",
       "...                                                   ...   \n",
       "131762  [O, O, O, O, O, O, O, O, O, other-law, O, O, o...   \n",
       "131763  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "131764   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "131765  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "131766  [O, O, O, O, O, O, O, location-GPE, O, O, loca...   \n",
       "\n",
       "                                      tags_coarse_grained  \\\n",
       "0                                            [O, O, O, O]   \n",
       "1       [O, O, person, O, O, O, person, person, O, per...   \n",
       "2       [O, art, O, O, O, O, O, O, O, O, O, O, O, O, O...   \n",
       "3       [O, O, O, O, O, O, O, organization, O, O, O, O...   \n",
       "4       [O, O, O, O, organization, organization, organ...   \n",
       "...                                                   ...   \n",
       "131762  [O, O, O, O, O, O, O, O, O, other, O, O, organ...   \n",
       "131763  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "131764   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "131765  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "131766  [O, O, O, O, O, O, O, location, O, O, location...   \n",
       "\n",
       "                                                 tags_ids  \\\n",
       "0       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1       [1, 1, 52, 1, 1, 1, 51, 51, 1, 51, 51, 1, 0, 0...   \n",
       "2       [1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3       [1, 1, 1, 1, 1, 1, 1, 33, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "4       [1, 1, 1, 1, 29, 29, 29, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                   ...   \n",
       "131762  [1, 1, 1, 1, 1, 1, 1, 1, 1, 48, 1, 1, 33, 33, ...   \n",
       "131763  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "131764  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "131765  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "131766  [1, 1, 1, 1, 1, 1, 1, 22, 1, 1, 22, 1, 1, 1, 1...   \n",
       "\n",
       "                                               tokens_ids  \n",
       "0       [586, 170, 711, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1       [35, 1601, 15202, 22, 659, 3, 1, 1, 6, 5586, 8...  \n",
       "2       [10, 2065, 10, 1045, 381, 2, 76, 11, 10, 9, 1,...  \n",
       "3       [5323, 5587, 6, 6537, 59, 603, 21, 1, 78, 1076...  \n",
       "4       [25, 187, 139, 3, 340, 22, 6282, 922, 2, 541, ...  \n",
       "...                                                   ...  \n",
       "131762  [25, 1235, 3, 2, 1110, 49, 40, 8312, 2, 14192,...  \n",
       "131763  [198, 53, 470, 47, 68, 17, 19121, 16, 8367, 38...  \n",
       "131764  [25, 2509, 29, 383, 57, 5299, 5, 2, 1, 28249, ...  \n",
       "131765  [12, 1, 3938, 7, 1, 391, 2, 1, 17656, 3, 5239,...  \n",
       "131766  [24359, 3, 29, 11, 2684, 17, 9, 604, 7094, 19,...  \n",
       "\n",
       "[131767 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = NERDataset(tr_titles)\n",
    "va_dataset = NERDataset(va_titles)\n",
    "\n",
    "tr_dataloader = DataLoader(dataset=tr_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "va_dataloader = DataLoader(dataset=va_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens_ids': tensor([586, 170, 711,   4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " 'tags_ids': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_embedding.weight         initialized w with Xavier            parameters #: 4442240\n",
      "lstm.weight_ih_l0              initialized w with Xavier            parameters #: 32768\n",
      "lstm.weight_hh_l0              initialized w with Xavier            parameters #: 16384\n",
      "lstm.weight_ih_l0_reverse      initialized w with Xavier            parameters #: 32768\n",
      "lstm.weight_hh_l0_reverse      initialized w with Xavier            parameters #: 16384\n",
      "fc.weight                      initialized w with Xavier            parameters #: 8704\n",
      "fc.bias                        initialized b with zero              parameters #: 68\n",
      "crf.start_transitions          initialized b with zero              parameters #: 68\n",
      "crf.end_transitions            initialized b with zero              parameters #: 68\n",
      "crf.transitions                initialized w with Xavier            parameters #: 4624\n",
      "BiLSTM_CRF(\n",
      "  (token_embedding): Embedding(34705, 128)\n",
      "  (lstm): LSTM(128, 64, bias=False, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=68, bias=True)\n",
      "  (crf): CRF(num_tags=68)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model = BiLSTM_CRF(\n",
    "    embed_size     = config.EMBED_SIZE,\n",
    "    hidden_size    = config.HIDDEN_SIZE, \n",
    "    dropout        = config.DROPOUT,\n",
    "    token_voc_size = len(TOKEN2IDX), \n",
    "    tag_voc_size   = len(TAG2IDX),\n",
    ").to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_folder = 'weights'\n",
    "if not os.path.exists(weights_folder):\n",
    "    os.makedirs(weights_folder)\n",
    "    \n",
    "runs_folder = '.runs'\n",
    "if not os.path.exists(runs_folder):\n",
    "    os.makedirs(runs_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1030 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crf loss: 13973.81 | regularization_loss 1.89 | total_loss 13975.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13/1030 [00:07<09:20,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.LR)\n",
    "\n",
    "# Make tensorboard writer\n",
    "writer = tensorboard.SummaryWriter(log_dir='./runs')\n",
    "\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "\n",
    "    # TRAINING PHASE\n",
    "    \n",
    "    tr_losses = []\n",
    "    \n",
    "    model.train()\n",
    "    for batch_num, tr_batch in tqdm(enumerate(tr_dataloader), total=tr_dataloader.__len__()):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        tr_xs = tr_batch['tokens_ids'].to(device)\n",
    "        tr_ys = tr_batch['tags_ids'].to(device)\n",
    "        \n",
    "        # Calculate loss\n",
    "        tr_emission_scores = model(x=tr_xs).to(device) # size: [batch=128, seq_len=100, 10]\n",
    "        tr_loss = model.loss_fn(emission_scores=tr_emission_scores, tags=tr_ys, mask=(tr_ys > 0).bool())\n",
    "        tr_losses.append(tr_loss.item())\n",
    "        \n",
    "        # Calculate total loss\n",
    "        regularization_loss = model.regularization_loss_fn(lam=config.REG_LAMBDA)\n",
    "        total_loss = tr_loss + regularization_loss\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f'crf loss: {tr_loss:.2f} | regularization_loss {regularization_loss:.2f} | total_loss {total_loss:.2f}')\n",
    "        \n",
    "        # Backward pass: compute gradient of the loss w.r.t. all learnable parameters\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Clip computed gradients\n",
    "#         if batch_num % 100 == 0:\n",
    "#             print('before')\n",
    "#             print(torch.max(torch.cat([p.grad.view(-1) for p in model.parameters()])))\n",
    "#             print(torch.min(torch.cat([p.grad.view(-1) for p in model.parameters()])))\n",
    "#             print(torch.norm(torch.cat([p.grad.view(-1) for p in model.parameters()])))\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=config.MAX_GRAD_NORM)\n",
    "#         if batch_num % 100 == 0:\n",
    "#             print('after')\n",
    "#             print(torch.max(torch.cat([p.grad.view(-1) for p in model.parameters()])))\n",
    "#             print(torch.min(torch.cat([p.grad.view(-1) for p in model.parameters()])))\n",
    "#             print(torch.norm(torch.cat([p.grad.view(-1) for p in model.parameters()])))\n",
    "        \n",
    "        # Optimize: update the weights using Adam optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "    # END TRAINING PHASE AND UPDATE LOG\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        print(f\"Epoch: {epoch:02d} | current NLL:{tr_loss.item():.2f} | avg NLL over batch:{np.mean(tr_losses):.2f}\")\n",
    "        writer.add_scalar('tr/'+'loss', np.mean(tr_losses), global_step=epoch)\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram('tr/' + name + '_weight', param.data, global_step=epoch)\n",
    "            writer.add_histogram('tr/' + name + '_grad', param.grad, global_step=epoch)\n",
    "        \n",
    "    # VALIDATION PHASE\n",
    "    \n",
    "    va_losses = []\n",
    "    \n",
    "    batch_preds = []\n",
    "    batch_trues = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for va_batch in tqdm(va_dataloader, total=va_dataloader.__len__()):\n",
    "            va_xs = va_batch['tokens_ids'].to(device) # size: [batch=128, seq_len=100]\n",
    "            va_ys = va_batch['tags_ids'].to(device) # size: [batch=128, seq_len=100]\n",
    "\n",
    "            # Forward pass: compute predicted output by passing input to the model\n",
    "            va_emission_scores = model(x=va_xs).to(device) # size: [batch=128, seq_len=100]\n",
    "            va_preds = torch.tensor(model.decode(va_emission_scores)).to(device)\n",
    "            va_loss = model.loss_fn(emission_scores=va_emission_scores, tags=va_ys, mask=(va_ys > 0).bool())\n",
    "            va_losses.append(va_loss.item())\n",
    "            \n",
    "            mask = (va_ys > 0).bool()\n",
    "\n",
    "            for row_id, true in enumerate(va_ys):\n",
    "                # do not count padding\n",
    "                true_tags = true[mask[row_id]]\n",
    "                # idx2tag\n",
    "                true_tags = [IDX2TAG[idx] for idx in true_tags.tolist()]\n",
    "                # convert to the format expected by seqeval\n",
    "                true_tags = io2bio(true_tags)\n",
    "                batch_trues.append(true_tags)\n",
    "\n",
    "            for row_id, pred in enumerate(va_preds):\n",
    "                # do not count padding\n",
    "                pred_tags = pred[mask[row_id]]\n",
    "                # idx2tag\n",
    "                pred_tags = [IDX2TAG[idx] for idx in pred_tags.tolist()]\n",
    "                # convert to the format expected by seqeval\n",
    "                pred_tags = io2bio(pred_tags)\n",
    "                batch_preds.append(pred_tags)\n",
    "        \n",
    "        for i in range(5):\n",
    "            print('pred:', batch_preds[i])\n",
    "            print('true:', batch_trues[i])\n",
    "            print()\n",
    "\n",
    "        print(\"va loss\", np.mean(va_losses))\n",
    "        writer.add_scalar(f'va/'+'loss', np.mean(va_losses), global_step=epoch)\n",
    "\n",
    "        report = classification_report(y_true=batch_trues, y_pred=batch_preds, zero_division=0)\n",
    "        print(report)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"weights/model_epoch_{epoch:02d}.pt\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 45\n",
    "# !tensorboard --logdir=artefacts/fine_grained/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
